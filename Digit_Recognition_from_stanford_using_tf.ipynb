{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_Recognition_from_stanford_using_tf.ipynb",
      "provenance": [],
      "mount_file_id": "1qeyHWedP_vDYxoNuLvmsW9x0oavEhSRd",
      "authorship_tag": "ABX9TyOBB1VbY/KB1zz/HY+HQoY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh-keswani/ML-DL-Basics/blob/main/Digit_Recognition_from_stanford_using_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcEZmoXFhXij"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from datetime import datetime\r\n",
        "from scipy.io import loadmat"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTye52rtKVjE"
      },
      "source": [
        "def convpool(X, W, b):\r\n",
        "    # just assume pool size is (2,2) because we need to augment it with 1s\r\n",
        "    conv_out = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\r\n",
        "    conv_out = tf.nn.bias_add(conv_out, b)\r\n",
        "    pool_out = tf.nn.max_pool(conv_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n",
        "    return tf.nn.relu(pool_out)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzBCVUTzLG9p"
      },
      "source": [
        "def init_filter(shape, poolsz):\r\n",
        "    #                                           except the last dimension since it is number of filters \r\n",
        "    w = np.random.randn(*shape) * np.sqrt(2.0 / np.prod(shape[:-1]))\r\n",
        "    return w.astype(np.float32)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib6htSeSLb_j"
      },
      "source": [
        "def rearrange(X):\r\n",
        "    # input is (32, 32, 3, N)\r\n",
        "    # output is (N, 32, 32, 3)\r\n",
        "    \r\n",
        "    return (X.transpose(3, 0, 1, 2) / 255).astype(np.float32)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVKmSUjLoyZn"
      },
      "source": [
        "# dataset from the http://ufldl.stanford.edu/housenumbers\r\n",
        "train = loadmat('train_32x32.mat')\r\n",
        "\r\n",
        "# Need to scale! don't leave as 0..255\r\n",
        "# Y is a N x 1 matrix with values 1..10 (MATLAB indexes by 1)\r\n",
        "# So flatten it and make it 0..9\r\n",
        "# Also need indicator matrix for cost calculation\r\n",
        "\r\n",
        "Xtrain = flatten(train['X'].astype(np.float32) / 255.)\r\n",
        "Ytrain = train['y'].flatten() - 1\r\n",
        "Xtrain, Ytrain = shuffle(Xtrain, Ytrain)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISQ_bxmmLyRy"
      },
      "source": [
        "# Need to scale! don't leave as 0..255\r\n",
        "# Y is a N x 1 matrix with values 1..10 (MATLAB indexes by 1)\r\n",
        "# So flatten it and make it 0..9\r\n",
        "# Also need indicator matrix for cost calculation\r\n",
        "\r\n",
        "Xtrain = rearrange(train['X'])\r\n",
        "Ytrain = train['y'].flatten() - 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CczkaRSzL5a0"
      },
      "source": [
        "# gradient descent params\r\n",
        "max_iter = 6\r\n",
        "print_period = 10\r\n",
        "N = Xtrain.shape[0]\r\n",
        "batch_sz = 128\r\n",
        "n_batches = N // batch_sz\r\n",
        "\r\n",
        "# limit samples since input will always have to be same size\r\n",
        "# you could also just do N = N / batch_sz * batch_sz\r\n",
        "Xtrain = Xtrain[:50000,]\r\n",
        "Ytrain = Ytrain[:50000]\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "036AZnZiRMK3",
        "outputId": "a107d5c3-fcd1-4231-8474-f31f8c8791c5"
      },
      "source": [
        "Xtrain.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yInR6b0KN2lW"
      },
      "source": [
        "# initial weights\r\n",
        "M = 500\r\n",
        "K = 10\r\n",
        "poolsz = (2, 2)\r\n",
        "\r\n",
        "W1_shape = (5, 5, 3, 20) # (filter_width, filter_height, num_color_channels, num_feature_maps)\r\n",
        "W1_init = init_filter(W1_shape, poolsz)\r\n",
        "b1_init = np.zeros(W1_shape[-1], dtype=np.float32) # one bias per output feature map\r\n",
        "\r\n",
        "W2_shape = (5, 5, 20, 50) # (filter_width, filter_height, old_num_feature_maps, num_feature_maps)\r\n",
        "W2_init = init_filter(W2_shape, poolsz)\r\n",
        "b2_init = np.zeros(W2_shape[-1], dtype=np.float32)\r\n",
        "\r\n",
        "# vanilla ANN weights\r\n",
        "#                         old_num_features ( flattened ) , num_of_neurons_in_this_layer\r\n",
        "W3_init = np.random.randn(W2_shape[-1]*8*8, M) / np.sqrt(W2_shape[-1]*8*8 + M)\r\n",
        "b3_init = np.zeros(M, dtype=np.float32)\r\n",
        "#                         old_neurons, n_classes\r\n",
        "W4_init = np.random.randn(M, K) / np.sqrt(M + K)\r\n",
        "b4_init = np.zeros(K, dtype=np.float32)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "K46QHfcXOdKX"
      },
      "source": [
        "# define variables and expressions\r\n",
        "# using None as the first shape element takes up too much RAM unfortunately\r\n",
        "\r\n",
        "X = tf.placeholder(tf.float32, shape=(batch_sz, 32, 32, 3), name='X')\r\n",
        "T = tf.placeholder(tf.int32, shape=(batch_sz,), name='T')\r\n",
        "W1 = tf.Variable(W1_init.astype(np.float32))\r\n",
        "b1 = tf.Variable(b1_init.astype(np.float32))\r\n",
        "W2 = tf.Variable(W2_init.astype(np.float32))\r\n",
        "b2 = tf.Variable(b2_init.astype(np.float32))\r\n",
        "W3 = tf.Variable(W3_init.astype(np.float32))\r\n",
        "b3 = tf.Variable(b3_init.astype(np.float32))\r\n",
        "W4 = tf.Variable(W4_init.astype(np.float32))\r\n",
        "b4 = tf.Variable(b4_init.astype(np.float32))\r\n",
        "\r\n",
        "params = [W1, b1, W2, b2, W3, b3, W4, b4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGQDZBkuPIP5"
      },
      "source": [
        "Z1 = convpool(X, W1, b1)\r\n",
        "Z2 = convpool(Z1, W2, b2)\r\n",
        "Z2_shape = Z2.get_shape().as_list()\r\n",
        "Z2r = tf.reshape(Z2, [Z2_shape[0], np.prod(Z2_shape[1:])])\r\n",
        "Z3 = tf.nn.relu( tf.matmul(Z2r, W3) + b3 )\r\n",
        "Yish = tf.matmul(Z3, W4) + b4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B7IzUDVPvmM"
      },
      "source": [
        "# L2 cost\r\n",
        "cost = tf.reduce_sum(\r\n",
        "    tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n",
        "        logits=Yish,\r\n",
        "        labels=T\r\n",
        "    )\r\n",
        ") + 0.01*sum(tf.reduce_sum(p*p) for p in params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUSKwg-P662"
      },
      "source": [
        "train_op = tf.train.RMSPropOptimizer(0.0001, decay=0.99, momentum=0.9).minimize(cost)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI1ry09ZQBNJ"
      },
      "source": [
        "# we'll use this to calculate the error rate\r\n",
        "predict_op = tf.argmax(Yish, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60JMOXPfQwfC"
      },
      "source": [
        "t0 = datetime.now()\r\n",
        "LL = []\r\n",
        "W1_val = None\r\n",
        "W2_val = None\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "with tf.Session() as session:\r\n",
        "    session.run(init)\r\n",
        "\r\n",
        "    for i in range(max_iter):\r\n",
        "        for j in range(n_batches):\r\n",
        "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\r\n",
        "            Ybatch = Ytrain[j*batch_sz:(j*batch_sz + batch_sz),]\r\n",
        "\r\n",
        "            if len(Xbatch) == batch_sz:\r\n",
        "                session.run(train_op, feed_dict={X: Xbatch, T: Ybatch})\r\n",
        "                if j % print_period == 0:\r\n",
        "                    # due to RAM limitations we need to have a fixed size input\r\n",
        "                    # so as a result, we have this ugly total cost and prediction computation\r\n",
        "                    test_cost = 0\r\n",
        "                    prediction = np.zeros(len(Xtest))\r\n",
        "                    for k in range(len(Xtest) // batch_sz):\r\n",
        "                        Xtestbatch = Xtest[k*batch_sz:(k*batch_sz + batch_sz),]\r\n",
        "                        Ytestbatch = Ytest[k*batch_sz:(k*batch_sz + batch_sz),]\r\n",
        "                        test_cost += session.run(cost, feed_dict={X: Xtestbatch, T: Ytestbatch})\r\n",
        "                        prediction[k*batch_sz:(k*batch_sz + batch_sz)] = session.run(\r\n",
        "                            predict_op, feed_dict={X: Xtestbatch})\r\n",
        "                        \r\n",
        "                    err = error_rate(prediction, Ytest)\r\n",
        "                    print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, test_cost, err))\r\n",
        "                    LL.append(test_cost)\r\n",
        "\r\n",
        "    W1_val = W1.eval()\r\n",
        "    W2_val = W2.eval()\r\n",
        "print(\"Elapsed time:\", (datetime.now() - t0))\r\n",
        "plt.plot(LL)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm02WkQ_SLPN"
      },
      "source": [
        "W1_val = W1_val.transpose(3, 2, 0, 1)\r\n",
        "W2_val = W2_val.transpose(3, 2, 0, 1)\r\n",
        "\r\n",
        "\r\n",
        "# visualize W1 (20, 3, 5, 5)\r\n",
        "# W1_val = W1.get_value()\r\n",
        "grid = np.zeros((8*5, 8*5))\r\n",
        "m = 0\r\n",
        "n = 0\r\n",
        "for i in range(20):\r\n",
        "    for j in range(3):\r\n",
        "        filt = W1_val[i,j]\r\n",
        "        grid[m*5:(m+1)*5,n*5:(n+1)*5] = filt\r\n",
        "        m += 1\r\n",
        "        if m >= 8:\r\n",
        "            m = 0\r\n",
        "            n += 1\r\n",
        "plt.imshow(grid, cmap='gray')\r\n",
        "plt.title(\"W1\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# visualize W2 (50, 20, 5, 5)\r\n",
        "# W2_val = W2.get_value()\r\n",
        "grid = np.zeros((32*5, 32*5))\r\n",
        "m = 0\r\n",
        "n = 0\r\n",
        "for i in range(50):\r\n",
        "    for j in range(20):\r\n",
        "        filt = W2_val[i,j]\r\n",
        "        grid[m*5:(m+1)*5,n*5:(n+1)*5] = filt\r\n",
        "        m += 1\r\n",
        "        if m >= 32:\r\n",
        "            m = 0\r\n",
        "            n += 1\r\n",
        "plt.imshow(grid, cmap='gray')\r\n",
        "plt.title(\"W2\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}